#+title: Parallel Programming
** Pre-requisite: C programming

* Notes on Parallel Programming using pthreads, openMP and open MPI.

** pthread concepts:
   - What is pthread?
     - pthread is an extension of C which allows us to write parallel programs by creating multiple threads in a shared memory architecture 


** open MPI concepts:
   - MPI is a library for message passing or communication between nodes/cores to perform parallel programming in Distributed Memory Architecture
   - Distributed Memory Architecture vs Shared Memory Architecture
   - What is a process?
   - MPI_Initialize, MPI_Finalize
   - What is rank?
   - What is size?
   - Communicator: A group that contains processes that can communicate with each other. 
     - MPI_COMM_WORLD is the default communicator
   - MPI functions
     - MPI_Send
     - MPI_Recv
   - MPI Communication Types:
     - Point to point communication:
       - If communication happens directly between two processes or more
       - Eg: Communication using MPI_Send() 
       - Blocking communication, Non-blocking communication
       - Synchronous communication, Asynchronous communication 
     - Collective communication:  
       - If all processes are part of the communication
       - Eg: Communcation using Broadcast (MPI_Bcast)
        
     
